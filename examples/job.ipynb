{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lume-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lume: Job Run Workflow \n",
    "\n",
    "This cookbook walks you through job creation, retreival, and running.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook covers the following topics:\n",
    "\n",
    "- **Creating and Running Jobs:** Learn how to define and use pipelines.\n",
    "\n",
    "- **Async CRUD operations:** Instructions on how to retreive a mapper from your created or retreived pipeline for efficient data processing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lume_py as lume\n",
    "\n",
    "lume.set_api_key(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage\n",
    "\n",
    "To see piplines created under your user account, the library must be configured to your account's api-key which can be available. You can set this up by replacing the api-key quote above. \n",
    "\n",
    "### Async\n",
    "\n",
    "Asynchronous versions of request-making methods are created by suffixing the method name with `async`. In order to retreive these functions in their usable state specify the `await` keyword\n",
    "\n",
    "```python\n",
    "# With Lume run await for any function! Tnis is because lume is a global client in its essence. \n",
    "jobs = await lume.Job.get_jobs_data_page()\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior Context\n",
    "\n",
    "This cookbook assumes a pipeline has already been created, called `ecomm_test`. The existing pipeline is meant to map source ecommerce data to an internal ecommerce data model. The target schema used in the pipeline is in this cookbook's folder, as `target_schema.json`. The cell below loads the target schema and source data (`source_schema.json`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "target_data_path = os.path.join(os.getcwd(), \"./data/target.json\")\n",
    "with open(target_data_path) as f:\n",
    "    target_data = json.load(f)\n",
    "\n",
    "source_data_path = os.path.join(os.getcwd(), \"./data/source.json\")\n",
    "with open(source_data_path) as f:\n",
    "    source_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create and Run Jobs\n",
    "By passing in your pipeline_id or pipeline_name and the associated data you can retrieve the result from running that job within that pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = await lume.Pipeline.get_pipeline_by_id(\"Name of the pipeline\")\n",
    "job = await lume.Job.create(source_data=source_data)\n",
    "await job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow - Multiple Job Runs\n",
    "\n",
    "- **For each job, you would typically prepare the source_data and then attach the job to the pipeline; this can be done with one line** \n",
    "- **Run Jobs with Concurrency** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "jobs_data = [\n",
    "    [{\"field1\": \"value1\"}, {\"field2\": \"value2\"}],\n",
    "    [{\"field1\": \"value3\"}, {\"field2\": \"value4\"}],\n",
    "]\n",
    "\n",
    "\n",
    "# Run all jobs concurrently\n",
    "async def run_all_jobs_concurrently(pipeline_id, jobs_data):\n",
    "    tasks = [lume.Job.create_and_run(pipeline_id, data) for data in jobs_data]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "\n",
    "results = await run_all_jobs_concurrently(pipeline.id, jobs_data)\n",
    "\n",
    "# Process the results\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Create a job for a created pipeline, and run that job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retreive Mappings via Result or through running the pipeline directly.\n",
    "```python\n",
    "await result.get_mappings()  # Retrieves the list of associated mappings associated with a specific result.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow - Seamless CRUD Management with Job Iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform bulk CRUD operations (shown below is an example of deleting all jobs)\n",
    "\n",
    "\n",
    "async def delete_all_jobs():\n",
    "    # Get all jobs (assuming this returns a list of job objects)\n",
    "    jobs = await lume.Job.get_jobs_data_page()\n",
    "\n",
    "    # Iterate directly over the list of jobs\n",
    "    for job in jobs:\n",
    "\n",
    "        # Update each job\n",
    "        await job.delete()\n",
    "        print(f\"Deleted job {job.id}\")  # Assuming 'id' is an attribute of the job\n",
    "\n",
    "\n",
    "# Run the function within an event loop\n",
    "if __name__ == \"__main__\":\n",
    "    import asyncio\n",
    "\n",
    "    asyncio.run(delete_all_jobs())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "terminus-3_N_Dp0V-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
